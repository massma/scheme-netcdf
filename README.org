* scheme-netcdf

Playing around with MIT/GNU Scheme's FFI, with the goal of getting netcdf functionality into mit-scheme.

** Prerequisites

1. netcdf libraries installed (I'm using version 4.4.1).
2. The script assumes gcc is aware of the location of netcdf headers and
   libraries.
3. MIT/GNU Scheme Version 9.2

** Build Instructions

1. clone repository
2. ~git submodule init && git submodule update~ load Alexey Radul's
      [[https://github.com/axch/test-manager][test-manager]] for make check.
3. ~make check~ builds package and runs some simple tests.

Note that everything /should/ just work if you installed MIT/GNU Scheme,
gcc, and netcdf through [[https://www.gnu.org/software/guix/][GNU Guix]]. If you do not use Guix as your package
manager, you might have to tweak the Makefile but that shouldn't be too
bad. Autotools might be added at some point, we'll see.

** Usage 
More documentation to come, also this is all still in development and
likely to change.

Make sure the repo's directory is in your library path (see --library in
[[info:mit-scheme-user#Unix%20Installation][documentation]]). To load package just run below:

#+BEGIN_SRC scheme
  (load-option 'ffi)
  (c-include "netcdf")
  (load "netcdf")
#+END_SRC

*** Basic functions

- ~(make-meta filename)~ :: load metadata from filename (output
     analogous to ~ncdump -h~).

- ~(make-var-data meta varname)~ :: load data variable structure
     (defined by the string ~varname~) from dataset described by meta
     (loaded with ~make-meta~).

- ~(get-keys structure)~ :: get list of all keys in ~structure~ .

- ~(get structure key)~ :: select element defined by ~key~ in
     ~structure~ .

- ~(index variable coords)~ :: return a new data variable structure
     indexed by ~coords~. Coords should be a list corresponding to the
     number of dimensions of variable. Each element of the coords list
     can be a symbol ~'all~ (for a slice with all coordinates of that
     dimension), a pair [~(low . high)~] for a slice of all coordinates
     between low and high, or a number, which indexed a single
     coordinate of that dimension. Note that coordinates do not have to
     be exact. The software will find the nearest coordinate value in
     the case of a single coordinate, and in the case of a ~(low
     . high)~ slice will take all coordinate between low and high,
     inclusive of low and high in the case that that coordinates exist
     that are equal to low and high. An example might be appropriate,
     see below.

     Alternatively, you can also name coordinates. The advantage of this
     is that you do not need to match the order of the coords list with
     the order of the data. To do this, pass an alist associating
     coordinate names with the values of coords you want, as above. Any
     coordinate name that is not included in the list will be selected
     assuming you want all coordinate values. See examples below.

     

** Index Example

Say we have a data variable structure called ~data~ of 3 dimensions
('x', 'y', 'z'), with each dimension having 5 coordinates equal to ~(0 1
2 3 4)~. We can index this with either un-named or named coordinate lists.

For un-named coordinate lists the index procedure is:

~(define new-data (index data '(all (1 . 3) 0))~

For named coordinate lists the index procedure is:

~(define new-data (index data '(("y" . (1 . 3)) ("z" . 0))~

Note that in the named example the order does not matter, but in the
un-named example the order of supplied coordinates must match the order
of the data's dimensions.

Both the index syntaxes would set ~new-data~ to a new data structure of
3 dimensions, of shape 5x3x1. This is represented internally as a
structure of shape 5x3, but the last coordinate is preserved in
new-data's structural element ~single-dimensions~. So this new data
structure would have the following characteristics:

#+BEGIN_SRC scheme
  (get new-data 'shape)
  ;; (5 3)
  (get new-data 'single-dimensions)
  ;; ('z'  0)
  (get new-data 'dimensions)
  ;; (('x' (0 1 2 3 4 5)) ('y' (1 2 3)))
#+END_SRC

